{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([[419, 151], [1026, 151], [1026, 284], [419, 284]],\n",
       "  'REMA 1000',\n",
       "  0.708197869881396),\n",
       " ([[487, 338], [812, 338], [812, 405], [487, 405]],\n",
       "  'Salgskvittering',\n",
       "  0.9999672191097156),\n",
       " ([[361, 461], [486, 461], [486, 515], [361, 515]],\n",
       "  'REMA',\n",
       "  0.9997764229774475),\n",
       " ([[516, 464], [621, 464], [621, 513], [516, 513]],\n",
       "  '1000',\n",
       "  0.9709287285804749),\n",
       " ([[651, 459], [900, 459], [900, 513], [651, 513]],\n",
       "  'MAJORSTUA',\n",
       "  0.9998091765601732),\n",
       " ([[421, 524], [488, 524], [488, 572], [421, 572]], 'MT', 0.9926070431703067),\n",
       " ([[532, 526], [775, 526], [775, 575], [532, 575]],\n",
       "  'DAGLIGVARE',\n",
       "  0.9981518857435556),\n",
       " ([[808, 529], [870, 529], [870, 578], [808, 578]], 'AS', 0.9944669040780405),\n",
       " ([[310, 581], [399, 581], [399, 629], [310, 629]], 'ORG', 0.9960464033515521),\n",
       " ([[440, 583], [518, 583], [518, 632], [440, 632]], 'NR:', 0.9144032196238746),\n",
       " ([[532, 583], [616, 583], [616, 635], [532, 635]], '260', 0.9999955263428388),\n",
       " ([[646, 581], [727, 581], [727, 629], [646, 629]], '358', 0.9657947421073914),\n",
       " ([[776, 583], [954, 583], [954, 635], [776, 635]],\n",
       "  '590 MVA',\n",
       "  0.8106584549650384),\n",
       " ([[507, 640], [816, 640], [816, 694], [507, 694]],\n",
       "  'Foretaksregisteret',\n",
       "  0.9999847708087052),\n",
       " ([[437, 700], [518, 700], [518, 748], [437, 748]],\n",
       "  'TLF:',\n",
       "  0.9992611408233643),\n",
       " ([[564, 705], [626, 705], [626, 756], [564, 756]], '99', 0.9863148880059437),\n",
       " ([[660, 706], [715, 706], [715, 750], [660, 750]], '81', 1.0),\n",
       " ([[743, 700], [868, 700], [868, 754], [743, 754]],\n",
       "  '20 34',\n",
       "  0.9933949938058904),\n",
       " ([[96, 822], [320, 822], [320, 873], [96, 873]],\n",
       "  '35.16.1973',\n",
       "  0.9798954161040788),\n",
       " ([[345, 816], [478, 816], [478, 873], [345, 873]],\n",
       "  '24.03',\n",
       "  0.8798084718810536),\n",
       " ([[927, 830], [1133, 830], [1133, 881], [927, 881]],\n",
       "  'Kasse:005',\n",
       "  0.9657853608667658),\n",
       " ([[126, 887], [383, 887], [383, 938], [126, 938]],\n",
       "  'Kvitt:481021',\n",
       "  0.9865354862501482),\n",
       " ([[911, 887], [1128, 887], [1128, 941], [911, 941]],\n",
       "  'OperNr:402',\n",
       "  0.7196426279359418),\n",
       " ([[139, 941], [440, 941], [440, 992], [139, 992]],\n",
       "  'Serienr.:519840',\n",
       "  0.9377671496908693),\n",
       " ([[828, 944], [1136, 944], [1136, 1006], [828, 1006]],\n",
       "  'Id:002011-005',\n",
       "  0.9844195937383297),\n",
       " ([[123, 1063], [228, 1063], [228, 1114], [123, 1114]],\n",
       "  'Saus',\n",
       "  0.9997680187225342),\n",
       " ([[357, 1060], [496, 1060], [496, 1113], [357, 1113]],\n",
       "  'gartneri',\n",
       "  0.9998910900868256),\n",
       " ([[813, 1068], [911, 1068], [911, 1117], [813, 1117]],\n",
       "  '159',\n",
       "  0.44993314290092246),\n",
       " ([[1098, 1071], [1206, 1071], [1206, 1122], [1098, 1122]],\n",
       "  '43,79',\n",
       "  0.9088820566494573),\n",
       " ([[84, 1122], [253, 1122], [253, 1175], [84, 1175]],\n",
       "  'Gourmet',\n",
       "  0.9998299056210423),\n",
       " ([[819, 1130], [914, 1130], [914, 1179], [819, 1179]],\n",
       "  '15%',\n",
       "  0.7756617304194302),\n",
       " ([[1096, 1131], [1200, 1131], [1200, 1175], [1096, 1175]],\n",
       "  '51,61',\n",
       "  0.47506070165333103),\n",
       " ([[127, 1186], [235, 1186], [235, 1241], [127, 1241]],\n",
       "  'Price',\n",
       "  0.9999834732592313),\n",
       " ([[819, 1187], [914, 1187], [914, 1236], [819, 1236]],\n",
       "  '159',\n",
       "  0.716155126533019),\n",
       " ([[1084, 1190], [1209, 1190], [1209, 1239], [1084, 1239]],\n",
       "  '772,59',\n",
       "  0.7683217473762302),\n",
       " ([[100, 1247], [367, 1247], [367, 1299], [100, 1299]],\n",
       "  'flerkornsblanding',\n",
       "  0.8811458388848974),\n",
       " ([[442, 1247], [559, 1247], [559, 1298], [442, 1298]],\n",
       "  'Foods',\n",
       "  0.9999680660428321),\n",
       " ([[822, 1250], [916, 1250], [916, 1298], [822, 1298]],\n",
       "  '15%',\n",
       "  0.4716908669841821),\n",
       " ([[1092, 1255], [1198, 1255], [1198, 1306], [1092, 1306]],\n",
       "  '15,72',\n",
       "  0.9983698282309437),\n",
       " ([[128, 1315], [231, 1315], [231, 1363], [128, 1363]],\n",
       "  'Mork',\n",
       "  0.999996542930603),\n",
       " ([[310, 1309], [366, 1309], [366, 1361], [310, 1361]],\n",
       "  'My',\n",
       "  0.9999964596665606),\n",
       " ([[413, 1301], [586, 1301], [586, 1358], [413, 1358]],\n",
       "  'Honning $',\n",
       "  0.7774799313979048),\n",
       " ([[813, 1309], [908, 1309], [908, 1358], [813, 1358]],\n",
       "  '159',\n",
       "  0.7682147566108924),\n",
       " ([[1112, 1318], [1208, 1318], [1208, 1360], [1112, 1360]],\n",
       "  '58,36',\n",
       "  0.6004038967210342),\n",
       " ([[135, 1364], [222, 1364], [222, 1408], [135, 1408]],\n",
       "  'style',\n",
       "  0.8643871131507616),\n",
       " ([[334, 1358], [440, 1358], [440, 1407], [334, 1407]],\n",
       "  '150G',\n",
       "  0.614325225353241),\n",
       " ([[819, 1361], [911, 1361], [911, 1409], [819, 1409]],\n",
       "  '159',\n",
       "  0.8247789595807666),\n",
       " ([[1107, 1364], [1202, 1364], [1202, 1408], [1107, 1408]],\n",
       "  '79,36',\n",
       "  0.7815610431437522),\n",
       " ([[62, 1413], [292, 1413], [292, 1457], [62, 1457]],\n",
       "  'Kanelsnurrer',\n",
       "  0.953070941753153),\n",
       " ([[819, 1404], [919, 1404], [919, 1455], [819, 1455]],\n",
       "  '159',\n",
       "  0.5884315707286437),\n",
       " ([[1107, 1408], [1202, 1408], [1202, 1449], [1107, 1449]],\n",
       "  '81,79',\n",
       "  0.6573254740920746),\n",
       " ([[65, 1455], [256, 1455], [256, 1504], [65, 1504]],\n",
       "  'Gelatinpulver',\n",
       "  0.94907897481181),\n",
       " ([[272, 1458], [429, 1458], [429, 1507], [272, 1507]],\n",
       "  'Nordfjord',\n",
       "  0.9958906474528647),\n",
       " ([[455, 1452], [579, 1452], [579, 1506], [455, 1506]],\n",
       "  'Sauce',\n",
       "  0.9999422319094433),\n",
       " ([[816, 1453], [914, 1453], [914, 1504], [816, 1504]],\n",
       "  '159',\n",
       "  0.9076035676298383),\n",
       " ([[1115, 1456], [1211, 1456], [1211, 1500], [1115, 1500]],\n",
       "  '22,93',\n",
       "  0.629050887004362),\n",
       " ([[88, 1553], [347, 1553], [347, 1607], [88, 1607]],\n",
       "  'Sum 8 varer',\n",
       "  0.9731204127956764),\n",
       " ([[1078, 1538], [1204, 1538], [1204, 1603], [1078, 1603]],\n",
       "  '44,35',\n",
       "  0.999902331825542),\n",
       " ([[63, 1694], [190, 1694], [190, 1751], [63, 1751]],\n",
       "  'BANK',\n",
       "  0.9998542070388794),\n",
       " ([[1076, 1694], [1190, 1694], [1190, 1745], [1076, 1745]],\n",
       "  '40,91',\n",
       "  0.7160994586003717),\n",
       " ([[74, 1797], [209, 1797], [209, 1851], [74, 1851]],\n",
       "  'Mva%',\n",
       "  0.9863337874412537),\n",
       " ([[390, 1791], [550, 1791], [550, 1846], [390, 1846]],\n",
       "  'Grunnlag',\n",
       "  0.9999668723497814),\n",
       " ([[757, 1799], [838, 1799], [838, 1848], [757, 1848]],\n",
       "  'Mva',\n",
       "  0.9999566400512343),\n",
       " ([[1074, 1797], [1190, 1797], [1190, 1848], [1074, 1848]],\n",
       "  'Totalt',\n",
       "  0.8740442209791355),\n",
       " ([[79, 1843], [193, 1843], [193, 1900], [79, 1900]],\n",
       "  '15,00',\n",
       "  0.8506412357331521),\n",
       " ([[438, 1852], [558, 1852], [558, 1893], [438, 1893]],\n",
       "  '204,43',\n",
       "  0.9979413478888819),\n",
       " ([[730, 1845], [835, 1845], [835, 1897], [730, 1897]],\n",
       "  '30,67',\n",
       "  0.6456243360848892),\n",
       " ([[1087, 1845], [1214, 1845], [1214, 1897], [1087, 1897]],\n",
       "  '235,10',\n",
       "  0.8867146280672926),\n",
       " ([[79, 1946], [350, 1946], [350, 2002], [79, 2002]],\n",
       "  '2023-10-02',\n",
       "  0.5763679611714615),\n",
       " ([[1109, 1948], [1228, 1948], [1228, 2000], [1109, 2000]],\n",
       "  '1829',\n",
       "  0.9999912977218628),\n",
       " ([[69, 2043], [280, 2043], [280, 2100], [69, 2100]],\n",
       "  'VAREKJOP',\n",
       "  0.9612537590812198),\n",
       " ([[933, 2046], [1027, 2046], [1027, 2100], [933, 2100]],\n",
       "  'NOK',\n",
       "  0.9643278414490246),\n",
       " ([[1079, 2051], [1217, 2051], [1217, 2103], [1079, 2103]],\n",
       "  '235.10',\n",
       "  0.9999857405494718),\n",
       " ([[102, 2095], [271, 2095], [271, 2140], [102, 2140]],\n",
       "  'BankAxept',\n",
       "  0.8419077468341409),\n",
       " ([[1076, 2103], [1225, 2103], [1225, 2157], [1076, 2157]],\n",
       "  'PSN:O1',\n",
       "  0.6965472038672702),\n",
       " ([[95, 2148], [318, 2148], [318, 2200], [95, 2200]],\n",
       "  'KONtAKTLos',\n",
       "  0.6180363472314967),\n",
       " ([[58, 2200], [163, 2200], [163, 2249], [58, 2249]],\n",
       "  'XXXX',\n",
       "  0.9967012405395508),\n",
       " ([[196, 2195], [310, 2195], [310, 2249], [196, 2249]],\n",
       "  'XXXX',\n",
       "  0.9955719709396362),\n",
       " ([[358, 2200], [467, 2200], [467, 2249], [358, 2249]],\n",
       "  'XXXX',\n",
       "  0.9935268759727478),\n",
       " ([[505, 2200], [616, 2200], [616, 2252], [505, 2252]],\n",
       "  'XX04',\n",
       "  0.8395394086837769),\n",
       " ([[637, 2198], [694, 2198], [694, 2249], [637, 2249]],\n",
       "  '57',\n",
       "  0.97765993852985),\n",
       " ([[69, 2246], [196, 2246], [196, 2298], [69, 2298]],\n",
       "  'TERM:',\n",
       "  0.9998904431007942),\n",
       " ([[816, 2246], [1198, 2246], [1198, 2300], [816, 2300]],\n",
       "  '75444624-128403',\n",
       "  0.9998517522597473),\n",
       " ([[66, 2292], [215, 2292], [215, 2341], [66, 2341]],\n",
       "  'NETSNO',\n",
       "  0.9996047578288315),\n",
       " ([[69, 2344], [217, 2344], [217, 2395], [69, 2395]],\n",
       "  '468177',\n",
       "  0.9965230873203327),\n",
       " ([[44, 2393], [125, 2393], [125, 2444], [44, 2444]],\n",
       "  'KC1',\n",
       "  0.7484926382567617),\n",
       " ([[74, 2447], [291, 2447], [291, 2498], [74, 2498]],\n",
       "  'ATC:00594',\n",
       "  0.903809172774653),\n",
       " ([[968, 2447], [1203, 2447], [1203, 2495], [968, 2495]],\n",
       "  'AED:201001',\n",
       "  0.9967405067270411),\n",
       " ([[55, 2496], [147, 2496], [147, 2544], [55, 2544]],\n",
       "  'AID:',\n",
       "  0.9754582047462463),\n",
       " ([[856, 2489], [1216, 2489], [1216, 2551], [856, 2551]],\n",
       "  'D5780000021010',\n",
       "  0.9520733473444533),\n",
       " ([[55, 2542], [215, 2542], [215, 2598], [55, 2598]],\n",
       "  'ARC:OO',\n",
       "  0.9859404919465516),\n",
       " ([[987, 2544], [1214, 2544], [1214, 2593], [987, 2593]],\n",
       "  'STATUS:000',\n",
       "  0.5548964045114086),\n",
       " ([[154, 2597], [420, 2597], [420, 2638], [154, 2638]],\n",
       "  'Autoriasionskode',\n",
       "  0.7513660864230706),\n",
       " ([[1074, 2593], [1239, 2593], [1239, 2650], [1074, 2650]],\n",
       "  '425909',\n",
       "  0.999991191266332),\n",
       " ([[77, 2647], [304, 2647], [304, 2699], [77, 2699]],\n",
       "  'REF:128403',\n",
       "  0.9998150848698077),\n",
       " ([[77, 2701], [266, 2701], [266, 2753], [77, 2753]],\n",
       "  'Resultat:',\n",
       "  0.9996812022059207),\n",
       " ([[981, 2699], [1195, 2699], [1195, 2753], [981, 2753]],\n",
       "  'Autorisert',\n",
       "  0.8922428148558113),\n",
       " ([[469, 2739], [776, 2739], [776, 2804], [469, 2804]],\n",
       "  'Behold kvittering',\n",
       "  0.9903099373191034),\n",
       " ([[431, 2797], [837, 2797], [837, 2859], [431, 2859]],\n",
       "  'KORTHOLDERS KOPI',\n",
       "  0.7196357493774708),\n",
       " ([[375, 3194], [488, 3194], [488, 3248], [375, 3248]],\n",
       "  'Takk',\n",
       "  0.7666907890542589),\n",
       " ([[516, 3197], [597, 3197], [597, 3254], [516, 3254]],\n",
       "  'for',\n",
       "  0.9999962145976122),\n",
       " ([[673, 3200], [887, 3200], [887, 3257], [673, 3257]],\n",
       "  'handelen',\n",
       "  0.9999854171463719),\n",
       " ([[331, 3251], [513, 3251], [513, 3300], [331, 3300]],\n",
       "  'facebook',\n",
       "  0.999345075569838),\n",
       " ([[597, 3259], [911, 3259], [911, 3313], [597, 3313]],\n",
       "  'com/REMA 1OOO',\n",
       "  0.6244800322884192),\n",
       " ([[473, 3291], [741, 3291], [741, 3371], [473, 3371]],\n",
       "  'Apningstider:',\n",
       "  0.9638360195232362),\n",
       " ([[448, 3362], [645, 3362], [645, 3419], [448, 3419]],\n",
       "  'Man-Lor;',\n",
       "  0.4796103739600271),\n",
       " ([[697, 3365], [813, 3365], [813, 3422], [697, 3422]],\n",
       "  '7-23',\n",
       "  0.7475964492112835)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import easyocr\n",
    "from easyocr.detection import get_detector, get_textbox\n",
    "import torch   \n",
    "import cv2\n",
    "\n",
    "# Load the custom detection model\n",
    "save_pth = torch.load(\"model/pretrain/CRAFT_clr_amp_29500.pth\")\n",
    "model = save_pth[\"craft\"]\n",
    "torch.save(model, \"craft_detection_model.pth\")\n",
    "\n",
    "# Initialize the EasyOCR reader with the custom detection model\n",
    "reader = easyocr.Reader(\n",
    "    lang_list=[\"en\"],\n",
    "    detector=False,\n",
    ")\n",
    "\n",
    "reader.get_detector, reader.get_textbox = get_detector, get_textbox\n",
    "reader.detector = reader.initDetector(\"craft_detection_model.pth\")\n",
    "\n",
    "# Read the image\n",
    "img = cv2.imread(\"CRAFT_data/ch4_test_images/561.jpg\")\n",
    "\n",
    "reader.readtext(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image with bounding boxes saved to output_with_bboxes.jpg\n"
     ]
    }
   ],
   "source": [
    "import easyocr\n",
    "from easyocr.detection import get_detector, get_textbox\n",
    "import torch   \n",
    "import cv2\n",
    "import numpy as np \n",
    "\n",
    "# Load the custom detection model\n",
    "# save_pth = torch.load(\"model/pretrain/CRAFT_clr_amp_29500.pth\")\n",
    "save_pth = torch.load(\"./exp/custom_data_train/CRAFT_clr_amp_100.pth\")\n",
    "model = save_pth[\"craft\"]\n",
    "torch.save(model, \"craft_detection_model.pth\")\n",
    "\n",
    "# Initialize the EasyOCR reader with the custom detection model\n",
    "reader = easyocr.Reader(\n",
    "    lang_list=[\"en\"],\n",
    "    detector=False,\n",
    ")\n",
    "\n",
    "reader.get_detector, reader.get_textbox = get_detector, get_textbox\n",
    "reader.detector = reader.initDetector(\"craft_detection_model.pth\")\n",
    "\n",
    "# Read the image\n",
    "img = cv2.imread(\"CRAFT_data/ch4_test_images/561.jpg\")\n",
    "\n",
    "# Perform text detection\n",
    "results = reader.readtext(img)\n",
    "\n",
    "# Draw bounding boxes and text on the image\n",
    "for result in results:\n",
    "    bbox, text, _ = result\n",
    "    bbox = np.array(bbox).astype(int)\n",
    "    cv2.polylines(img, [bbox], isClosed=True, color=(0, 255, 0), thickness=2)\n",
    "    cv2.putText(img, text, (bbox[0][0], bbox[0][1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "# Save or display the image\n",
    "output_file = \"output_with_bboxes.jpg\"\n",
    "cv2.imwrite(output_file, img)\n",
    "# Alternatively, to display the image\n",
    "# cv2.imshow(\"Detected Text\", img)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "print(f\"Image with bounding boxes saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataParallel' object has no attribute 'detect'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 71\u001b[0m\n\u001b[1;32m     68\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCRAFT_data/ch4_test_images/561.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# Get the bounding boxes\u001b[39;00m\n\u001b[0;32m---> 71\u001b[0m horizontal_list_agg, free_list_agg \u001b[38;5;241m=\u001b[39m \u001b[43mdetect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# Draw bounding boxes on the image\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m bbox_list \u001b[38;5;129;01min\u001b[39;00m horizontal_list_agg \u001b[38;5;241m+\u001b[39m free_list_agg:\n",
      "Cell \u001b[0;32mIn[4], line 31\u001b[0m, in \u001b[0;36mdetect\u001b[0;34m(detector, img, min_size, text_threshold, low_text, link_threshold, canvas_size, mag_ratio, slope_ths, ycenter_ths, height_ths, width_ths, add_margin, reformat, optimal_num_chars, threshold, bbox_min_score, bbox_min_size, max_candidates)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reformat:\n\u001b[1;32m     29\u001b[0m     img, img_cv_grey \u001b[38;5;241m=\u001b[39m easyocr\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mreformat_input(img)\n\u001b[0;32m---> 31\u001b[0m text_box_list \u001b[38;5;241m=\u001b[39m \u001b[43mdetector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect\u001b[49m(\n\u001b[1;32m     32\u001b[0m     img, min_size\u001b[38;5;241m=\u001b[39mmin_size,\n\u001b[1;32m     33\u001b[0m     text_threshold\u001b[38;5;241m=\u001b[39mtext_threshold,\n\u001b[1;32m     34\u001b[0m     link_threshold\u001b[38;5;241m=\u001b[39mlink_threshold,\n\u001b[1;32m     35\u001b[0m     low_text\u001b[38;5;241m=\u001b[39mlow_text,\n\u001b[1;32m     36\u001b[0m     canvas_size\u001b[38;5;241m=\u001b[39mcanvas_size,\n\u001b[1;32m     37\u001b[0m     mag_ratio\u001b[38;5;241m=\u001b[39mmag_ratio,\n\u001b[1;32m     38\u001b[0m     slope_ths\u001b[38;5;241m=\u001b[39mslope_ths,\n\u001b[1;32m     39\u001b[0m     ycenter_ths\u001b[38;5;241m=\u001b[39mycenter_ths,\n\u001b[1;32m     40\u001b[0m     height_ths\u001b[38;5;241m=\u001b[39mheight_ths,\n\u001b[1;32m     41\u001b[0m     width_ths\u001b[38;5;241m=\u001b[39mwidth_ths,\n\u001b[1;32m     42\u001b[0m     add_margin\u001b[38;5;241m=\u001b[39madd_margin,\n\u001b[1;32m     43\u001b[0m     reformat\u001b[38;5;241m=\u001b[39mreformat,\n\u001b[1;32m     44\u001b[0m     optimal_num_chars\u001b[38;5;241m=\u001b[39moptimal_num_chars,\n\u001b[1;32m     45\u001b[0m     threshold\u001b[38;5;241m=\u001b[39mthreshold,\n\u001b[1;32m     46\u001b[0m     bbox_min_score\u001b[38;5;241m=\u001b[39mbbox_min_score,\n\u001b[1;32m     47\u001b[0m     bbox_min_size\u001b[38;5;241m=\u001b[39mbbox_min_size,\n\u001b[1;32m     48\u001b[0m     max_candidates\u001b[38;5;241m=\u001b[39mmax_candidates\n\u001b[1;32m     49\u001b[0m )\n\u001b[1;32m     51\u001b[0m horizontal_list_agg, free_list_agg \u001b[38;5;241m=\u001b[39m [], []\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text_box \u001b[38;5;129;01min\u001b[39;00m text_box_list:\n",
      "File \u001b[0;32m~/miniconda3/envs/py8/lib/python3.8/site-packages/torch/nn/modules/module.py:1614\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1612\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1613\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1614\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1615\u001b[0m     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataParallel' object has no attribute 'detect'"
     ]
    }
   ],
   "source": [
    "import easyocr\n",
    "from easyocr.detection import get_detector\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np  # Make sure numpy is imported\n",
    "\n",
    "# Load the custom detection model\n",
    "save_pth = torch.load(\"exp/custom_data_train/CRAFT_clr_amp_100.pth\")\n",
    "model = save_pth[\"craft\"]\n",
    "torch.save(model, \"craft_detection_model.pth\")\n",
    "\n",
    "# Initialize the EasyOCR reader with the custom detection model\n",
    "reader = easyocr.Reader(\n",
    "    lang_list=[\"en\"],\n",
    "    detector=False,\n",
    ")\n",
    "\n",
    "reader.get_detector = get_detector\n",
    "reader.detector = reader.initDetector(\"craft_detection_model.pth\")\n",
    "\n",
    "# Define the detect function based on the provided EasyOCR code\n",
    "def detect(detector, img, min_size=20, text_threshold=0.7, low_text=0.4,\n",
    "           link_threshold=0.4, canvas_size=2560, mag_ratio=1.0,\n",
    "           slope_ths=0.1, ycenter_ths=0.5, height_ths=0.5,\n",
    "           width_ths=0.5, add_margin=0.1, reformat=True, optimal_num_chars=None,\n",
    "           threshold=0.2, bbox_min_score=0.2, bbox_min_size=3, max_candidates=0):\n",
    "\n",
    "    if reformat:\n",
    "        img, img_cv_grey = easyocr.utils.reformat_input(img)\n",
    "\n",
    "    text_box_list = detector.detect(\n",
    "        img, min_size=min_size,\n",
    "        text_threshold=text_threshold,\n",
    "        link_threshold=link_threshold,\n",
    "        low_text=low_text,\n",
    "        canvas_size=canvas_size,\n",
    "        mag_ratio=mag_ratio,\n",
    "        slope_ths=slope_ths,\n",
    "        ycenter_ths=ycenter_ths,\n",
    "        height_ths=height_ths,\n",
    "        width_ths=width_ths,\n",
    "        add_margin=add_margin,\n",
    "        reformat=reformat,\n",
    "        optimal_num_chars=optimal_num_chars,\n",
    "        threshold=threshold,\n",
    "        bbox_min_score=bbox_min_score,\n",
    "        bbox_min_size=bbox_min_size,\n",
    "        max_candidates=max_candidates\n",
    "    )\n",
    "\n",
    "    horizontal_list_agg, free_list_agg = [], []\n",
    "    for text_box in text_box_list:\n",
    "        horizontal_list, free_list = easyocr.utils.group_text_box(\n",
    "            text_box, slope_ths, ycenter_ths, height_ths,\n",
    "            width_ths, add_margin, (optimal_num_chars is None)\n",
    "        )\n",
    "        if min_size:\n",
    "            horizontal_list = [i for i in horizontal_list if max(\n",
    "                i[1] - i[0], i[3] - i[2]) > min_size]\n",
    "            free_list = [i for i in free_list if max(\n",
    "                easyocr.utils.diff([c[0] for c in i]), easyocr.utils.diff([c[1] for c in i])) > min_size]\n",
    "        horizontal_list_agg.append(horizontal_list)\n",
    "        free_list_agg.append(free_list)\n",
    "\n",
    "    return horizontal_list_agg, free_list_agg\n",
    "\n",
    "# Read the image\n",
    "img = cv2.imread(\"CRAFT_data/ch4_test_images/561.jpg\")\n",
    "\n",
    "# Get the bounding boxes\n",
    "horizontal_list_agg, free_list_agg = detect(reader.detector, img)\n",
    "\n",
    "# Draw bounding boxes on the image\n",
    "for bbox_list in horizontal_list_agg + free_list_agg:\n",
    "    for bbox in bbox_list:\n",
    "        pts = np.array(bbox, np.int32).reshape((-1, 1, 2))\n",
    "        cv2.polylines(img, [pts], isClosed=True, color=(0, 255, 0), thickness=2)\n",
    "\n",
    "# Save or display the image\n",
    "cv2.imwrite(\"output_with_bboxes.jpg\", img)\n",
    "# Alternatively, to display the image\n",
    "# cv2.imshow(\"Detected Text\", img)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataParallel' object has no attribute 'detect'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 59\u001b[0m\n\u001b[1;32m     56\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCRAFT_data/ch4_test_images/561.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# Get the bounding boxes\u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m bboxes \u001b[38;5;241m=\u001b[39m \u001b[43mdetect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Draw bounding boxes on the image\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m bbox \u001b[38;5;129;01min\u001b[39;00m bboxes:\n",
      "Cell \u001b[0;32mIn[2], line 33\u001b[0m, in \u001b[0;36mdetect\u001b[0;34m(detector, img, min_size, text_threshold, low_text, link_threshold, canvas_size, mag_ratio, slope_ths, ycenter_ths, height_ths, width_ths, add_margin, reformat, optimal_num_chars, threshold, bbox_min_score, bbox_min_size, max_candidates)\u001b[0m\n\u001b[1;32m     30\u001b[0m     img, img_cv_grey \u001b[38;5;241m=\u001b[39m easyocr\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mreformat_input(img)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Perform text detection using the detector directly\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m bboxes \u001b[38;5;241m=\u001b[39m \u001b[43mdetector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect\u001b[49m(\n\u001b[1;32m     34\u001b[0m     img, min_size\u001b[38;5;241m=\u001b[39mmin_size,\n\u001b[1;32m     35\u001b[0m     text_threshold\u001b[38;5;241m=\u001b[39mtext_threshold,\n\u001b[1;32m     36\u001b[0m     link_threshold\u001b[38;5;241m=\u001b[39mlink_threshold,\n\u001b[1;32m     37\u001b[0m     low_text\u001b[38;5;241m=\u001b[39mlow_text,\n\u001b[1;32m     38\u001b[0m     canvas_size\u001b[38;5;241m=\u001b[39mcanvas_size,\n\u001b[1;32m     39\u001b[0m     mag_ratio\u001b[38;5;241m=\u001b[39mmag_ratio,\n\u001b[1;32m     40\u001b[0m     slope_ths\u001b[38;5;241m=\u001b[39mslope_ths,\n\u001b[1;32m     41\u001b[0m     ycenter_ths\u001b[38;5;241m=\u001b[39mycenter_ths,\n\u001b[1;32m     42\u001b[0m     height_ths\u001b[38;5;241m=\u001b[39mheight_ths,\n\u001b[1;32m     43\u001b[0m     width_ths\u001b[38;5;241m=\u001b[39mwidth_ths,\n\u001b[1;32m     44\u001b[0m     add_margin\u001b[38;5;241m=\u001b[39madd_margin,\n\u001b[1;32m     45\u001b[0m     reformat\u001b[38;5;241m=\u001b[39mreformat,\n\u001b[1;32m     46\u001b[0m     optimal_num_chars\u001b[38;5;241m=\u001b[39moptimal_num_chars,\n\u001b[1;32m     47\u001b[0m     threshold\u001b[38;5;241m=\u001b[39mthreshold,\n\u001b[1;32m     48\u001b[0m     bbox_min_score\u001b[38;5;241m=\u001b[39mbbox_min_score,\n\u001b[1;32m     49\u001b[0m     bbox_min_size\u001b[38;5;241m=\u001b[39mbbox_min_size,\n\u001b[1;32m     50\u001b[0m     max_candidates\u001b[38;5;241m=\u001b[39mmax_candidates\n\u001b[1;32m     51\u001b[0m )\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m bboxes\n",
      "File \u001b[0;32m~/miniconda3/envs/py8/lib/python3.8/site-packages/torch/nn/modules/module.py:1614\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1612\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1613\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1614\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1615\u001b[0m     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataParallel' object has no attribute 'detect'"
     ]
    }
   ],
   "source": [
    "import easyocr\n",
    "from easyocr.detection import get_detector\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the custom detection model\n",
    "save_pth = torch.load(\"exp/custom_data_train/CRAFT_clr_amp_100.pth\")\n",
    "model = save_pth[\"craft\"]\n",
    "torch.save(model, \"craft_detection_model.pth\")\n",
    "\n",
    "# Initialize the EasyOCR reader with the custom detection model\n",
    "reader = easyocr.Reader(\n",
    "    lang_list=[\"en\"],\n",
    "    detector=False,\n",
    ")\n",
    "\n",
    "# Set custom detector and load model\n",
    "reader.get_detector = get_detector\n",
    "reader.detector = reader.initDetector(\"craft_detection_model.pth\")\n",
    "\n",
    "# Define the detect function based on the provided EasyOCR code\n",
    "def detect(detector, img, min_size=20, text_threshold=0.7, low_text=0.4,\n",
    "           link_threshold=0.4, canvas_size=2560, mag_ratio=1.0,\n",
    "           slope_ths=0.1, ycenter_ths=0.5, height_ths=0.5,\n",
    "           width_ths=0.5, add_margin=0.1, reformat=True, optimal_num_chars=None,\n",
    "           threshold=0.2, bbox_min_score=0.2, bbox_min_size=3, max_candidates=0):\n",
    "\n",
    "    if reformat:\n",
    "        img, img_cv_grey = easyocr.utils.reformat_input(img)\n",
    "\n",
    "    # Perform text detection using the detector directly\n",
    "    bboxes = detector.detect(\n",
    "        img, min_size=min_size,\n",
    "        text_threshold=text_threshold,\n",
    "        link_threshold=link_threshold,\n",
    "        low_text=low_text,\n",
    "        canvas_size=canvas_size,\n",
    "        mag_ratio=mag_ratio,\n",
    "        slope_ths=slope_ths,\n",
    "        ycenter_ths=ycenter_ths,\n",
    "        height_ths=height_ths,\n",
    "        width_ths=width_ths,\n",
    "        add_margin=add_margin,\n",
    "        reformat=reformat,\n",
    "        optimal_num_chars=optimal_num_chars,\n",
    "        threshold=threshold,\n",
    "        bbox_min_score=bbox_min_score,\n",
    "        bbox_min_size=bbox_min_size,\n",
    "        max_candidates=max_candidates\n",
    "    )\n",
    "\n",
    "    return bboxes\n",
    "\n",
    "# Read the image\n",
    "img = cv2.imread(\"CRAFT_data/ch4_test_images/561.jpg\")\n",
    "\n",
    "# Get the bounding boxes\n",
    "bboxes = detect(reader.detector, img)\n",
    "\n",
    "# Draw bounding boxes on the image\n",
    "for bbox in bboxes:\n",
    "    pts = np.array(bbox, np.int32).reshape((-1, 1, 2))\n",
    "    cv2.polylines(img, [pts], isClosed=True, color=(0, 255, 0), thickness=2)\n",
    "\n",
    "# Save or display the image\n",
    "cv2.imwrite(\"output_with_bboxes.jpg\", img)\n",
    "# Alternatively, to display the image\n",
    "# cv2.imshow(\"Detected Text\", img)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
